{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparkify Project Workspace\n",
    "\n",
    "This workspace contains a tiny subset (128MB) of the full dataset available (12GB). This notebook is used to explore a smaller subset with Spark before running on the cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from pyspark.sql import SparkSession, Window\n",
    "from pyspark import SparkFiles\n",
    "from pyspark.sql.functions import avg, col, concat, count, desc, \\\n",
    "asc, explode, lit, min, max, split, stddev, udf, isnan, when, rank, \\\n",
    "log, sqrt, cbrt, exp\n",
    "from pyspark.sql.functions import sum as Fsum\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression, \\\n",
    "RandomForestClassifier, GBTClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "\n",
    "from pyspark.ml.feature import CountVectorizer, IDF, Normalizer, \\\n",
    "PCA, RegexTokenizer, Tokenizer, StandardScaler, StopWordsRemover, \\\n",
    "StringIndexer, VectorAssembler, MaxAbsScaler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "from time import time\n",
    "import re\n",
    "import numpy as np\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import scatter_matrix\n",
    "import seaborn as sns\n",
    "import random\n",
    "%matplotlib inline\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName(\"Sparkify\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Clean Dataset\n",
    "\n",
    "### 1.1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(artist='Martha Tilston', auth='Logged In', firstName='Colin', gender='M', itemInSession=50, lastName='Freeman', length=277.89016, level='paid', location='Bakersfield, CA', method='PUT', page='NextSong', registration=1538173362000, sessionId=29, song='Rockpools', status=200, ts=1538352117000, userAgent='Mozilla/5.0 (Windows NT 6.1; WOW64; rv:31.0) Gecko/20100101 Firefox/31.0', userId='30')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load from local source as a pilot study\n",
    "path = 'mini_sparkify_event_data.json'\n",
    "df = spark.read.json(path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- artist: string (nullable = true)\n",
      " |-- auth: string (nullable = true)\n",
      " |-- firstName: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- itemInSession: long (nullable = true)\n",
      " |-- lastName: string (nullable = true)\n",
      " |-- length: double (nullable = true)\n",
      " |-- level: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- method: string (nullable = true)\n",
      " |-- page: string (nullable = true)\n",
      " |-- registration: long (nullable = true)\n",
      " |-- sessionId: long (nullable = true)\n",
      " |-- song: string (nullable = true)\n",
      " |-- status: long (nullable = true)\n",
      " |-- ts: long (nullable = true)\n",
      " |-- userAgent: string (nullable = true)\n",
      " |-- userId: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows in the dataset: 286500.\n",
      "\n",
      "artist: 58392 missing values.         0 NaN's; 58392 Null's; 0 empty strings.\n",
      "firstName: 8346 missing values.         0 NaN's; 8346 Null's; 0 empty strings.\n",
      "gender: 8346 missing values.         0 NaN's; 8346 Null's; 0 empty strings.\n",
      "lastName: 8346 missing values.         0 NaN's; 8346 Null's; 0 empty strings.\n",
      "length: 58392 missing values.         0 NaN's; 58392 Null's; 0 empty strings.\n",
      "location: 8346 missing values.         0 NaN's; 8346 Null's; 0 empty strings.\n",
      "registration: 8346 missing values.         0 NaN's; 8346 Null's; 0 empty strings.\n",
      "song: 58392 missing values.         0 NaN's; 58392 Null's; 0 empty strings.\n",
      "userAgent: 8346 missing values.         0 NaN's; 8346 Null's; 0 empty strings.\n",
      "userId: 8346 missing values.         0 NaN's; 0 Null's; 8346 empty strings.\n"
     ]
    }
   ],
   "source": [
    "# Examine the number of missing values in each column\n",
    "print(f\"Total number of rows in the dataset: {df.count()}.\\n\")\n",
    "missing_count_total = 0\n",
    "\n",
    "for coln in df.columns:\n",
    "    missing_count = df.filter((isnan(df[coln])) | (df[coln].isNull()) | (df[coln] == \"\")).count()\n",
    "    \n",
    "    if missing_count > 0:\n",
    "        nan_count = df.filter(isnan(df[coln])).count()\n",
    "        null_count = df.filter(df[coln].isNull()).count()\n",
    "        empty_str = df.filter(df[coln] == \"\").count()\n",
    "        print(f\"{coln}: {missing_count} missing values. \\\n",
    "        {nan_count} NaN's; {null_count} Null's; {empty_str} empty strings.\")\n",
    "        missing_count_total += missing_count\n",
    "        \n",
    "if missing_count_total == 0:\n",
    "    print(\"No missing values.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing values in `userId` and `sessionId`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 286500 rows in the dataset.\n",
      "There are 0 NaN's in either userId or sessionId. These rows are dropped.\n"
     ]
    }
   ],
   "source": [
    "# Remove rows that have NaN in either userId or sessionId\n",
    "num_rows = df.count()\n",
    "print(f\"There are {df.count()} rows in the dataset.\")\n",
    "df = df.dropna(how='any', subset=['userId', 'sessionId'])\n",
    "print(f\"There are {num_rows - df.count()} NaN's in either userId or sessionId. These rows are dropped.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|userId|\n",
      "+------+\n",
      "|      |\n",
      "|    10|\n",
      "|   100|\n",
      "|100001|\n",
      "|100002|\n",
      "+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Preview the values of useId\n",
    "df.select(['userId']).dropDuplicates().orderBy(df['userId']).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An `userId` of empty string looks suspicious. To figure out what's going on, I'm going to look at the `page` events for empty `userId`'s in comparison with all `userId`'s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a view to run SQL queries\n",
    "df.createOrReplaceTempView(\"df_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|               page|\n",
      "+-------------------+\n",
      "|               Home|\n",
      "|              About|\n",
      "|Submit Registration|\n",
      "|              Login|\n",
      "|           Register|\n",
      "|               Help|\n",
      "|              Error|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# page events of users whose userId IS an empty string\n",
    "spark.sql(\n",
    "    '''\n",
    "    SELECT DISTINCT page\n",
    "    FROM df_table\n",
    "    WHERE userId == \"\"\n",
    "    '''\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                page|\n",
      "+--------------------+\n",
      "|              Cancel|\n",
      "|    Submit Downgrade|\n",
      "|         Thumbs Down|\n",
      "|           Downgrade|\n",
      "|         Roll Advert|\n",
      "|              Logout|\n",
      "|       Save Settings|\n",
      "|Cancellation Conf...|\n",
      "|            Settings|\n",
      "|     Add to Playlist|\n",
      "|          Add Friend|\n",
      "|            NextSong|\n",
      "|           Thumbs Up|\n",
      "|             Upgrade|\n",
      "|      Submit Upgrade|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# page events of users whose userId is NOT an empty string\n",
    "spark.sql(\n",
    "    '''\n",
    "    SELECT DISTINCT page\n",
    "    FROM df_table\n",
    "    EXCEPT\n",
    "    SELECT DISTINCT page\n",
    "    FROM df_table\n",
    "    WHERE userId == \"\"\n",
    "    '''\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An `userId` of empty string likely represents user(s) who are in the middle of or prior to sign-in or registration. Therefore, the rows corresponding to empty `userId` are dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows that have empty userId\n",
    "df = df.filter(df['userId'] != \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because `sessionId` column is numeric, we don't need to worry about empty string problem for this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values:\n",
      "    userId: 0 missing values.\n",
      "    sessionId: 0 missing values.\n",
      "    firstName: 0 missing values.\n",
      "    gender: 0 missing values.\n",
      "    lastName: 0 missing values.\n",
      "    location: 0 missing values.\n",
      "    registration: 0 missing values.\n",
      "    userAgent: 0 missing values.\n"
     ]
    }
   ],
   "source": [
    "# Check the number of missing values in userId and sessionId\n",
    "print(\"Number of missing values:\")\n",
    "for coln in ['userId', 'sessionId', 'firstName', 'gender', 'lastName', 'location', 'registration', 'userAgent']:\n",
    "    missing_count = df.filter((isnan(df[coln])) | (df[coln].isNull()) | (df[coln] == \"\")).count()\n",
    "    print(f\"    {coln}: {missing_count} missing values.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing values in `artist`, `length`, `song`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                page|\n",
      "+--------------------+\n",
      "|              Cancel|\n",
      "|    Submit Downgrade|\n",
      "|         Thumbs Down|\n",
      "|                Home|\n",
      "|           Downgrade|\n",
      "|         Roll Advert|\n",
      "|              Logout|\n",
      "|       Save Settings|\n",
      "|Cancellation Conf...|\n",
      "|               About|\n",
      "|            Settings|\n",
      "|     Add to Playlist|\n",
      "|          Add Friend|\n",
      "|           Thumbs Up|\n",
      "|                Help|\n",
      "|             Upgrade|\n",
      "|               Error|\n",
      "|      Submit Upgrade|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# page events of null artist values\n",
    "df.filter(df['artist'].isNull()).select(df['page']).dropDuplicates().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|    page|\n",
      "+--------+\n",
      "|NextSong|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# page events of NOT null artist values\n",
    "df.filter(df['artist'].isNotNull()).select(df['page']).dropDuplicates().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that only page event \"NextSong\", i.e. playing a song, has corresponding artist information, which makes sense. This should apply for each of the `artist`, `length`, and `song` columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When page event is 'NextSong':\n",
      "    artist: 0 missing values.\n",
      "    length: 0 missing values.\n",
      "    song: 0 missing values.\n"
     ]
    }
   ],
   "source": [
    "# Check the number of missing values of artist, length, song columns when page event is \"NextSong\"\n",
    "df_song = df.filter(df['page'] == \"NextSong\")\n",
    "print(\"When page event is 'NextSong':\")\n",
    "for coln in ['artist', 'length', 'song']:\n",
    "    missing_count = df_song.filter((isnan(df[coln])) | (df[coln].isNull()) | (df[coln] == \"\")).count()\n",
    "    print(f\"    {coln}: {missing_count} missing values.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis (EDA)\n",
    "\n",
    "Perform EDA using a small subset of the full dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Overview of numerical columns\n",
    "\n",
    "A quick look at descriptive statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Overview of non-numerical columns\n",
    "\n",
    "A quick look at the possible categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Define churn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Explore data\n",
    "Analyze the behavior for users who stayed vs users who churned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering\n",
    "\n",
    "In this section, I'm going to build out the features that I think useful to train my model on. First, I'm going to do pilot experiment on a small subset of the full dataset. Then, I will use the code on the full dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Final Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
